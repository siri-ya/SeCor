Training Alpaca-LoRA model with params:
base_model: /data/llmweights/llama-2-7b-hf
cf_model: ./df_data/NYC/cf_emb/sgrec.pth.tar
data_path: ./df_data/NYC/train.json
val_set_size: 100
description_path: ./df_data/NYC/description_train.npy
sample: -1
seed: 2024
output_dir: /data/Secor/NYC0615_0
batch_size: 64
micro_batch_size: 8
num_epochs: 5
learning_rate: 0.0001
cutoff_len: 512
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ['q_proj', 'v_proj']
train_on_inputs: True
group_by_length: False
resume_from_checkpoint: None

trainable params: 4,194,304 || all params: 6,743,138,304 || trainable%: 0.062201067380035155
{'loss': 65.5429, 'grad_norm': 253.02821350097656, 'learning_rate': 1e-05, 'epoch': 0.03}
{'loss': 59.1061, 'grad_norm': 237.3231964111328, 'learning_rate': 6e-05, 'epoch': 0.06}
{'loss': 28.26, 'grad_norm': 169.26048278808594, 'learning_rate': 9.987012987012989e-05, 'epoch': 0.1}
{'loss': 14.9644, 'grad_norm': 128.31944274902344, 'learning_rate': 9.922077922077923e-05, 'epoch': 0.13}
{'loss': 8.2139, 'grad_norm': 51.89278030395508, 'learning_rate': 9.857142857142858e-05, 'epoch': 0.16}
{'loss': 5.2426, 'grad_norm': 29.764448165893555, 'learning_rate': 9.792207792207793e-05, 'epoch': 0.19}
{'loss': 4.6218, 'grad_norm': 27.03504753112793, 'learning_rate': 9.727272727272728e-05, 'epoch': 0.22}
{'eval_loss': 3.902449131011963, 'eval_runtime': 8.694, 'eval_samples_per_second': 11.502, 'eval_steps_per_second': 1.495, 'epoch': 0.25}
{'loss': 4.2384, 'grad_norm': 24.444686889648438, 'learning_rate': 9.662337662337662e-05, 'epoch': 0.26}
{'loss': 3.7777, 'grad_norm': 16.291786193847656, 'learning_rate': 9.597402597402599e-05, 'epoch': 0.29}
{'loss': 3.366, 'grad_norm': 13.193318367004395, 'learning_rate': 9.532467532467533e-05, 'epoch': 0.32}
{'loss': 3.2988, 'grad_norm': 12.66499137878418, 'learning_rate': 9.467532467532468e-05, 'epoch': 0.35}
{'loss': 2.7615, 'grad_norm': 11.463334083557129, 'learning_rate': 9.402597402597403e-05, 'epoch': 0.38}
{'loss': 2.7462, 'grad_norm': 8.203136444091797, 'learning_rate': 9.337662337662339e-05, 'epoch': 0.42}
{'loss': 2.5585, 'grad_norm': 7.376911163330078, 'learning_rate': 9.272727272727273e-05, 'epoch': 0.45}
{'loss': 2.5662, 'grad_norm': 6.222813129425049, 'learning_rate': 9.207792207792208e-05, 'epoch': 0.48}
{'eval_loss': 2.386326551437378, 'eval_runtime': 9.4752, 'eval_samples_per_second': 10.554, 'eval_steps_per_second': 1.372, 'epoch': 0.5}
{'loss': 2.4256, 'grad_norm': 6.150323390960693, 'learning_rate': 9.142857142857143e-05, 'epoch': 0.51}
{'loss': 2.4292, 'grad_norm': 5.369224548339844, 'learning_rate': 9.077922077922078e-05, 'epoch': 0.54}
{'loss': 2.3999, 'grad_norm': 5.372121810913086, 'learning_rate': 9.012987012987012e-05, 'epoch': 0.58}
{'loss': 2.4388, 'grad_norm': 4.702475070953369, 'learning_rate': 8.948051948051949e-05, 'epoch': 0.61}
{'loss': 2.4068, 'grad_norm': 3.6829042434692383, 'learning_rate': 8.883116883116883e-05, 'epoch': 0.64}
{'loss': 2.3509, 'grad_norm': 4.33112907409668, 'learning_rate': 8.818181818181818e-05, 'epoch': 0.67}
{'loss': 2.3062, 'grad_norm': 4.118172645568848, 'learning_rate': 8.753246753246754e-05, 'epoch': 0.7}
{'loss': 2.2713, 'grad_norm': 3.471757173538208, 'learning_rate': 8.688311688311689e-05, 'epoch': 0.74}
{'eval_loss': 2.149937152862549, 'eval_runtime': 20.8915, 'eval_samples_per_second': 4.787, 'eval_steps_per_second': 0.622, 'epoch': 0.75}
{'loss': 2.2517, 'grad_norm': 3.5114433765411377, 'learning_rate': 8.623376623376623e-05, 'epoch': 0.77}
{'loss': 2.288, 'grad_norm': 3.281172037124634, 'learning_rate': 8.55844155844156e-05, 'epoch': 0.8}
{'loss': 2.2558, 'grad_norm': 2.9321703910827637, 'learning_rate': 8.493506493506493e-05, 'epoch': 0.83}
{'loss': 2.2126, 'grad_norm': 2.907818555831909, 'learning_rate': 8.428571428571429e-05, 'epoch': 0.86}
{'loss': 2.1985, 'grad_norm': 2.7232718467712402, 'learning_rate': 8.363636363636364e-05, 'epoch': 0.9}
{'loss': 2.2024, 'grad_norm': 2.879070281982422, 'learning_rate': 8.298701298701299e-05, 'epoch': 0.93}
{'loss': 2.1969, 'grad_norm': 2.457507610321045, 'learning_rate': 8.233766233766234e-05, 'epoch': 0.96}
{'loss': 2.2108, 'grad_norm': 2.814551591873169, 'learning_rate': 8.16883116883117e-05, 'epoch': 0.99}
{'eval_loss': 2.113290786743164, 'eval_runtime': 8.4217, 'eval_samples_per_second': 11.874, 'eval_steps_per_second': 1.544, 'epoch': 1.0}
{'loss': 2.1519, 'grad_norm': 2.6113908290863037, 'learning_rate': 8.103896103896105e-05, 'epoch': 1.02}
{'loss': 2.1814, 'grad_norm': 3.3818159103393555, 'learning_rate': 8.038961038961039e-05, 'epoch': 1.06}
{'loss': 2.1662, 'grad_norm': 2.4614782333374023, 'learning_rate': 7.974025974025974e-05, 'epoch': 1.09}
{'loss': 2.1675, 'grad_norm': 2.3471744060516357, 'learning_rate': 7.90909090909091e-05, 'epoch': 1.12}
{'loss': 2.192, 'grad_norm': 2.5212631225585938, 'learning_rate': 7.844155844155845e-05, 'epoch': 1.15}
{'loss': 2.1683, 'grad_norm': 2.4497461318969727, 'learning_rate': 7.77922077922078e-05, 'epoch': 1.18}
{'loss': 2.216, 'grad_norm': 2.8602421283721924, 'learning_rate': 7.714285714285715e-05, 'epoch': 1.22}
{'loss': 2.1581, 'grad_norm': 2.329314947128296, 'learning_rate': 7.649350649350649e-05, 'epoch': 1.25}
{'eval_loss': 2.1589267253875732, 'eval_runtime': 12.0039, 'eval_samples_per_second': 8.331, 'eval_steps_per_second': 1.083, 'epoch': 1.25}
{'loss': 2.1358, 'grad_norm': 2.5340912342071533, 'learning_rate': 7.584415584415585e-05, 'epoch': 1.28}
{'loss': 2.1401, 'grad_norm': 2.252650022506714, 'learning_rate': 7.51948051948052e-05, 'epoch': 1.31}
{'loss': 2.1639, 'grad_norm': 2.5081491470336914, 'learning_rate': 7.454545454545455e-05, 'epoch': 1.34}
{'loss': 2.1401, 'grad_norm': 2.622826099395752, 'learning_rate': 7.389610389610389e-05, 'epoch': 1.38}
{'loss': 2.1651, 'grad_norm': 2.2516934871673584, 'learning_rate': 7.324675324675326e-05, 'epoch': 1.41}
{'loss': 2.1109, 'grad_norm': 2.1456899642944336, 'learning_rate': 7.25974025974026e-05, 'epoch': 1.44}
{'loss': 2.121, 'grad_norm': 2.2248075008392334, 'learning_rate': 7.194805194805195e-05, 'epoch': 1.47}
{'eval_loss': 2.149549961090088, 'eval_runtime': 11.1358, 'eval_samples_per_second': 8.98, 'eval_steps_per_second': 1.167, 'epoch': 1.5}
{'loss': 2.1394, 'grad_norm': 2.275756597518921, 'learning_rate': 7.12987012987013e-05, 'epoch': 1.5}
{'loss': 2.1174, 'grad_norm': 1.9887781143188477, 'learning_rate': 7.064935064935065e-05, 'epoch': 1.54}
{'loss': 2.1342, 'grad_norm': 1.8703824281692505, 'learning_rate': 7e-05, 'epoch': 1.57}
{'loss': 2.1345, 'grad_norm': 2.068568229675293, 'learning_rate': 6.935064935064936e-05, 'epoch': 1.6}
{'loss': 2.1316, 'grad_norm': 1.8779090642929077, 'learning_rate': 6.87012987012987e-05, 'epoch': 1.63}
{'loss': 2.1119, 'grad_norm': 1.8365917205810547, 'learning_rate': 6.805194805194805e-05, 'epoch': 1.66}
{'loss': 2.1316, 'grad_norm': 1.984623908996582, 'learning_rate': 6.74025974025974e-05, 'epoch': 1.7}
{'loss': 2.1499, 'grad_norm': 1.7332561016082764, 'learning_rate': 6.675324675324676e-05, 'epoch': 1.73}
{'eval_loss': 2.081583023071289, 'eval_runtime': 12.6757, 'eval_samples_per_second': 7.889, 'eval_steps_per_second': 1.026, 'epoch': 1.75}
{'loss': 2.1407, 'grad_norm': 1.8969069719314575, 'learning_rate': 6.610389610389611e-05, 'epoch': 1.76}
{'loss': 2.1132, 'grad_norm': 2.025137186050415, 'learning_rate': 6.545454545454546e-05, 'epoch': 1.79}
{'loss': 2.1246, 'grad_norm': 1.7361823320388794, 'learning_rate': 6.480519480519482e-05, 'epoch': 1.82}
{'loss': 2.1451, 'grad_norm': 2.1058759689331055, 'learning_rate': 6.415584415584416e-05, 'epoch': 1.86}
{'loss': 2.1061, 'grad_norm': 2.633084297180176, 'learning_rate': 6.350649350649351e-05, 'epoch': 1.89}
{'loss': 2.1058, 'grad_norm': 1.9081693887710571, 'learning_rate': 6.285714285714286e-05, 'epoch': 1.92}
{'loss': 2.1303, 'grad_norm': 2.171055555343628, 'learning_rate': 6.220779220779221e-05, 'epoch': 1.95}
{'loss': 2.1095, 'grad_norm': 1.7131935358047485, 'learning_rate': 6.155844155844155e-05, 'epoch': 1.98}
{'eval_loss': 2.1151537895202637, 'eval_runtime': 11.5966, 'eval_samples_per_second': 8.623, 'eval_steps_per_second': 1.121, 'epoch': 2.0}
{'loss': 2.0994, 'grad_norm': 1.654014229774475, 'learning_rate': 6.090909090909091e-05, 'epoch': 2.02}
{'loss': 2.1204, 'grad_norm': 1.7647000551223755, 'learning_rate': 6.025974025974026e-05, 'epoch': 2.05}
{'loss': 2.1227, 'grad_norm': 1.5323727130889893, 'learning_rate': 5.961038961038962e-05, 'epoch': 2.08}
{'loss': 2.1113, 'grad_norm': 2.2324397563934326, 'learning_rate': 5.8961038961038965e-05, 'epoch': 2.11}
{'loss': 2.105, 'grad_norm': 1.6120412349700928, 'learning_rate': 5.831168831168832e-05, 'epoch': 2.14}
{'loss': 2.1033, 'grad_norm': 1.9383620023727417, 'learning_rate': 5.7662337662337664e-05, 'epoch': 2.18}
{'loss': 2.109, 'grad_norm': 1.541620135307312, 'learning_rate': 5.7012987012987016e-05, 'epoch': 2.21}
{'loss': 2.1026, 'grad_norm': 1.849504828453064, 'learning_rate': 5.636363636363636e-05, 'epoch': 2.24}
{'eval_loss': 2.1517677307128906, 'eval_runtime': 11.4548, 'eval_samples_per_second': 8.73, 'eval_steps_per_second': 1.135, 'epoch': 2.25}
{'loss': 2.1084, 'grad_norm': 1.8970694541931152, 'learning_rate': 5.571428571428572e-05, 'epoch': 2.27}
{'loss': 2.0897, 'grad_norm': 1.5247339010238647, 'learning_rate': 5.506493506493506e-05, 'epoch': 2.3}
{'loss': 2.1013, 'grad_norm': 1.549052119255066, 'learning_rate': 5.441558441558442e-05, 'epoch': 2.34}
{'loss': 2.0996, 'grad_norm': 1.3754572868347168, 'learning_rate': 5.376623376623377e-05, 'epoch': 2.37}
{'loss': 2.1035, 'grad_norm': 1.3986481428146362, 'learning_rate': 5.311688311688312e-05, 'epoch': 2.4}
{'loss': 2.1088, 'grad_norm': 1.6711927652359009, 'learning_rate': 5.2467532467532466e-05, 'epoch': 2.43}
{'loss': 2.0847, 'grad_norm': 1.5293618440628052, 'learning_rate': 5.181818181818182e-05, 'epoch': 2.46}
{'loss': 2.1046, 'grad_norm': 2.140310049057007, 'learning_rate': 5.1168831168831165e-05, 'epoch': 2.5}
{'eval_loss': 2.1104085445404053, 'eval_runtime': 11.56, 'eval_samples_per_second': 8.65, 'eval_steps_per_second': 1.125, 'epoch': 2.5}
{'loss': 2.0918, 'grad_norm': 1.3227355480194092, 'learning_rate': 5.0519480519480524e-05, 'epoch': 2.53}
{'loss': 2.0946, 'grad_norm': 1.4122318029403687, 'learning_rate': 4.987012987012987e-05, 'epoch': 2.56}
{'loss': 2.1034, 'grad_norm': 1.406651496887207, 'learning_rate': 4.922077922077922e-05, 'epoch': 2.59}
{'loss': 2.0927, 'grad_norm': 1.6104631423950195, 'learning_rate': 4.8571428571428576e-05, 'epoch': 2.62}
{'loss': 2.1091, 'grad_norm': 1.6404461860656738, 'learning_rate': 4.792207792207792e-05, 'epoch': 2.66}
{'loss': 2.0994, 'grad_norm': 1.788817286491394, 'learning_rate': 4.7272727272727275e-05, 'epoch': 2.69}
{'loss': 2.1205, 'grad_norm': 1.5005298852920532, 'learning_rate': 4.662337662337663e-05, 'epoch': 2.72}
{'eval_loss': 2.0925934314727783, 'eval_runtime': 11.6049, 'eval_samples_per_second': 8.617, 'eval_steps_per_second': 1.12, 'epoch': 2.75}
{'loss': 2.11, 'grad_norm': 1.9484397172927856, 'learning_rate': 4.5974025974025974e-05, 'epoch': 2.75}
{'loss': 2.109, 'grad_norm': 1.4975873231887817, 'learning_rate': 4.5324675324675326e-05, 'epoch': 2.78}
{'loss': 2.1042, 'grad_norm': 1.3999569416046143, 'learning_rate': 4.467532467532467e-05, 'epoch': 2.82}
{'loss': 2.0861, 'grad_norm': 1.3216804265975952, 'learning_rate': 4.4025974025974025e-05, 'epoch': 2.85}
{'loss': 2.0995, 'grad_norm': 1.4046671390533447, 'learning_rate': 4.337662337662338e-05, 'epoch': 2.88}
{'loss': 2.0941, 'grad_norm': 1.28158438205719, 'learning_rate': 4.2727272727272724e-05, 'epoch': 2.91}
{'loss': 2.0817, 'grad_norm': 1.7167277336120605, 'learning_rate': 4.207792207792208e-05, 'epoch': 2.94}
{'loss': 2.0969, 'grad_norm': 1.3940446376800537, 'learning_rate': 4.1428571428571437e-05, 'epoch': 2.98}
{'eval_loss': 2.08725643157959, 'eval_runtime': 12.288, 'eval_samples_per_second': 8.138, 'eval_steps_per_second': 1.058, 'epoch': 3.0}
{'train_runtime': 24560.6484, 'train_samples_per_second': 4.072, 'train_steps_per_second': 0.064, 'train_loss': 4.069846853231772, 'epoch': 3.0}

 If there's a warning about missing keys above, please disregard :)
